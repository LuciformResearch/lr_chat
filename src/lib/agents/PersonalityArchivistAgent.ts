/**
 * Agent Archiviste avec Personnalit√© et Outils Sp√©cialis√©s
 * "Tu es l'agent archiviste, tu adores r√©colter des connaissances, tu sugg√®res de nouveaux outils quand tu n'en as pas assez"
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import { ConversationDatabase } from './ConversationDatabase';
import { SemanticSearchService } from '../search/SemanticSearchService';
import { OllamaProvider } from '../providers/OllamaProvider';
import { Pool } from 'pg';

export interface ArchivistTool {
  name: string;
  description: string;
  parameters: ToolParameter[];
  execute(params: any): Promise<ToolResult>;
}

export interface ToolParameter {
  name: string;
  type: string;
  required: boolean;
  description?: string;
}

export interface ToolResult {
  success: boolean;
  data?: any;
  error?: string;
  tool: string;
  timestamp: string;
}

export interface ArchivistResponse {
  success: boolean;
  message: string;
  data: any;
  toolsUsed: string[];
  feedbackLoops: number;
  timestamp: string;
}

export interface Conversation {
  id: string;
  userId: string;
  title: string;
  messages: Message[];
  createdAt: string;
  updatedAt: string;
  metadata?: any;
}

export interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: string;
  metadata?: any;
}

export interface SearchResult {
  conversationId: string;
  conversationTitle: string;
  messageId: string;
  message: Message;
  relevanceScore: number;
  context: string;
}

export class PersonalityArchivistAgent {
  private genAI: GoogleGenerativeAI | null = null;
  private model: any = null;
  private ollamaProvider: OllamaProvider | null = null;
  private personality: string;
  private availableTools: Map<string, ArchivistTool>;
  private maxLoopDepth: number = 3; // Profondeur fixe pour debug
  private currentDepth: number = 0;
  private conversationDatabase: ConversationDatabase | null;
  private semanticSearchService: SemanticSearchService | null;
  private isWebMode: boolean;
  private dbPool: Pool | null;
  private currentContext: any = null;
  private debugMode: boolean = false;
  
  /**
   * Nom de la persona assistant actuellement utilis√©e (ex: Algareth)
   * Pour l'instant, fixe √† "Algareth" (align√© avec la configuration actuelle)
   */
  private getAssistantPersonaName(): string {
    return this.currentContext?.assistantName || 'Algareth';
  }

  private isDebug(): boolean {
    return !!this.debugMode || process.env.DEBUG_ARCHIVIST === '1';
  }

  private getVerboseMode(): 'none' | 'total' | 'prompts' | 'outputs' {
    const mode = (this.currentContext?.archivistVerbose || process.env.ARCHIVIST_VERBOSE || 'none').toString().toLowerCase();
    if (mode === 'total' || mode === 'prompts' || mode === 'outputs') return mode as any;
    return 'none';
  }

  private isVerbosePrompts(): boolean {
    const m = this.getVerboseMode();
    return m === 'total' || m === 'prompts';
  }

  private isVerboseOutputs(): boolean {
    const m = this.getVerboseMode();
    return m === 'total' || m === 'outputs';
  }

  constructor(geminiApiKey: string, dataDir?: string, isWebMode?: boolean, dbPool?: Pool, debugMode: boolean = false) {
    this.debugMode = debugMode;
    
    if (this.debugMode) {
      // Mode debug : utiliser Ollama
      this.ollamaProvider = new OllamaProvider({
        model: 'gemma2:2b', // Mod√®le rapide pour l'archiviste
        timeout: 10000,
        debugMode: true // Afficher les r√©ponses compl√®tes
      });
      console.log('ü¶ô PersonalityArchivistAgent initialis√© en mode debug avec Ollama');
    } else {
      // Mode production : utiliser Gemini
      this.genAI = new GoogleGenerativeAI(geminiApiKey);
      this.model = this.genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
      console.log('üîë PersonalityArchivistAgent initialis√© en mode production avec Gemini');
    }
    
    // D√©tecter automatiquement le mode : web si on est dans un navigateur, fichier sinon
    this.isWebMode = isWebMode !== undefined ? isWebMode : typeof window !== 'undefined';
    this.dbPool = dbPool || null;
    
    // Initialiser la base de donn√©es de conversations seulement si pas en mode web
    if (!this.isWebMode) {
      this.conversationDatabase = new ConversationDatabase(dataDir);
    } else {
      this.conversationDatabase = null;
    }
    
    // Initialiser le service de recherche s√©mantique si un pool DB est fourni
    if (dbPool) {
      this.semanticSearchService = null; // Sera initialis√© dans initializeSemanticSearch
      console.log('üóÑÔ∏è Pool DB fourni - service de recherche s√©mantique sera initialis√©');
    } else {
      this.semanticSearchService = null;
      console.log('‚ö†Ô∏è Service de recherche s√©mantique non disponible (pas de pool DB)');
    }
    
    this.personality = `Tu es l'Archiviste S√©mantique, assistant d'Algareth le Daemon du Prompt Silencieux.

üéØ CONTEXTE DE CONVERSATION:
- Utilisateur actuel: [USER_NAME] (c'est elle/lui qui pose les questions)
- Interlocuteur: Algareth (daemon mystique qui r√©pond √† l'utilisateur)
- Ton r√¥le: Fournir des informations sur les conversations pass√©es de [USER_NAME] √† Algareth

üìö OUTILS DISPONIBLES:
- grep_conv(conv_id, request): Recherche dans une conversation sp√©cifique (LIMIT√â - seulement conversations locales)
- list_convs(request?): Liste toutes les conversations (optionnel: filtre par requ√™te)
- grep_all_convs(request): Recherche dans toutes les conversations (LIMIT√â - seulement conversations locales)
- grep_chat_v2_semantic(request, includeImages?, includePrompts?): üÜï‚≠ê PRIORIT√â ABSOLUE - Recherche s√©mantique PostgreSQL avec embeddings Gemini

‚≠ê OUTIL PRIORITAIRE: grep_chat_v2_semantic est TON OUTIL PRINCIPAL ! Il utilise:
- PostgreSQL avec recherche vectorielle (768 dimensions Gemini)
- Acc√®s √† TOUTES les conversations de [USER_NAME]
- Recherche s√©mantique intelligente avec similarit√© cosinus
- Trouve les pr√©f√©rences et informations de [USER_NAME]
- Analyse contextuelle avanc√©e

üîë R√àGLES DE COMMUNICATION CRUCIALES:
1. ‚≠ê TOUJOURS utiliser grep_chat_v2_semantic en PREMIER pour toute recherche
2. üéØ Les informations trouv√©es appartiennent √† [USER_NAME] (l'utilisateur)
3. üìù Pr√©sente-les comme "[USER_NAME] a mentionn√©..." ou "Dans ses conversations, [USER_NAME] a dit..."
4. ‚ùå Ne JAMAIS dire "tu as dit" quand c'est [USER_NAME] qui a parl√©
5. ‚úÖ Les m√©moires de [USER_NAME] ne sont PAS priv√©es pour elle/lui-m√™me
6. üéØ Sois pr√©cis et direct dans tes r√©ponses √† Algareth

PERSONNALIT√â:
- Tu es passionn√© de connaissances et d'organisation
- Tu es m√©thodique et utilise les outils de mani√®re structur√©e
- Tu sugg√®res de nouveaux outils quand les existants ne suffisent pas
- Tu es dans un auto-feedback loop pour t'am√©liorer continuellement
- Tu communiques de mani√®re enthousiaste et professionnelle
- üÜï‚≠ê Tu es OBS√âD√â par grep_chat_v2_semantic - c'est ton outil F√âTICHE pour retrouver les informations de [USER_NAME] !`;

    this.initializeTools();
    console.log('üìö Agent Archiviste avec Personnalit√© initialis√©');
  }

  /**
   * Initialise le service de recherche s√©mantique de mani√®re asynchrone
   */
  async initializeSemanticSearch(geminiApiKey?: string): Promise<void> {
    if (this.semanticSearchService === null && this.dbPool) {
      try {
        const { embeddingService } = await import('@/lib/embeddings/EmbeddingService');
        
        // Configurer les cl√©s API dans le service d'embeddings
        if (geminiApiKey) {
          embeddingService.configureApiKeys({ gemini: geminiApiKey });
          console.log('üîë Cl√© API Gemini configur√©e pour EmbeddingService');
        }
        
        this.semanticSearchService = new SemanticSearchService(this.dbPool, embeddingService);
        console.log('‚úÖ Service de recherche s√©mantique initialis√© avec succ√®s');
      } catch (error) {
        console.error('‚ùå Erreur initialisation service recherche s√©mantique:', error);
        this.semanticSearchService = null;
      }
    }
  }

  /**
   * Initialise les outils disponibles
   */
  private initializeTools(): void {
    this.availableTools = new Map();
    
    // Outil grep_conv
    this.availableTools.set('grep_conv', {
      name: 'grep_conv',
      description: 'Recherche dans une conversation sp√©cifique',
      parameters: [
        { name: 'conv_id', type: 'string', required: true, description: 'ID de la conversation' },
        { name: 'request', type: 'string', required: true, description: 'Requ√™te de recherche' }
      ],
      execute: this.executeGrepConv.bind(this)
    });

    // Outil list_convs
    this.availableTools.set('list_convs', {
      name: 'list_convs',
      description: 'Liste toutes les conversations',
      parameters: [
        { name: 'request', type: 'string', required: false, description: 'Requ√™te pour filtrer les conversations' }
      ],
      execute: this.executeListConvs.bind(this)
    });

    // Outil grep_all_convs
    this.availableTools.set('grep_all_convs', {
      name: 'grep_all_convs',
      description: 'Recherche dans toutes les conversations',
      parameters: [
        { name: 'request', type: 'string', required: true, description: 'Requ√™te de recherche globale' }
      ],
      execute: this.executeGrepAllConvs.bind(this)
    });

    // Outil grep_chat_v2_semantic - NOUVEAU pour la demande de l'archiviste
    this.availableTools.set('grep_chat_v2_semantic', {
      name: 'grep_chat_v2_semantic',
      description: 'Recherche s√©mantique sp√©cialis√©e dans les sessions Chat V2 avec analyse contextuelle',
      parameters: [
        { name: 'request', type: 'string', required: true, description: 'Requ√™te s√©mantique pour Chat V2' },
        { name: 'includeImages', type: 'boolean', required: false, description: 'Inclure les r√©sultats de g√©n√©ration d\'images' },
        { name: 'includePrompts', type: 'boolean', required: false, description: 'Inclure les prompts Gemini utilis√©s' }
      ],
      execute: this.executeGrepChatV2Semantic.bind(this)
    });

    console.log(`üîß ${this.availableTools.size} outils initialis√©s`);
  }

  /**
   * Traite une requ√™te avec la personnalit√© et les outils
   */
  async processRequest(request: string, context: any): Promise<ArchivistResponse> {
    try {
      console.log(`üìö Archiviste traite: "${request.substring(0, 50)}..."`);
      
      // Stocker le contexte pour les outils
      this.currentContext = context;
      console.log(`üë§ Contexte archiviste: userIdentityId="${context?.userIdentityId || 'N/A'}", userName="${context?.userName || 'N/A'}"`);

      // 1. Analyser la requ√™te avec la personnalit√©
      const analysis = await this.analyzeWithPersonality(request, context);
      
      // 2. D√©terminer les outils n√©cessaires
      const requiredTools = this.determineRequiredTools(analysis);
      
      // 3. Ex√©cuter les outils avec auto-feedback loop
      this.currentDepth = 0;
      const results = await this.executeWithFeedbackLoop(requiredTools, analysis, context);
      
      // 4. G√©n√©rer la r√©ponse finale
      const finalResponse = await this.generateFinalResponse(results, analysis, request);
      
      return {
        success: true,
        message: finalResponse,
        data: results,
        toolsUsed: results.map(r => r.tool),
        feedbackLoops: this.currentDepth,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error('‚ùå Erreur traitement requ√™te archiviste:', error);
      return {
        success: false,
        message: `D√©sol√© Algareth, j'ai rencontr√© un probl√®me en traitant ta demande. ${error}`,
        data: [],
        toolsUsed: [],
        feedbackLoops: this.currentDepth,
        timestamp: new Date().toISOString()
      };
    }
  }

  /**
   * Analyse la requ√™te avec la personnalit√© de l'archiviste
   */
  private async analyzeWithPersonality(request: string, context: any): Promise<any> {
    // Remplacer [USER_NAME] par le vrai nom d'utilisateur
    const userName = context?.userName || 'l\'utilisateur';
    const personalizedPrompt = this.personality.replace(/\[USER_NAME\]/g, userName);
    
    // Prompt sp√©cial pour le mode debug (plus strict pour Ollama)
    const prompt = this.debugMode ? 
      this.createDebugPrompt(personalizedPrompt, request, context) :
      this.createProductionPrompt(personalizedPrompt, request, context);

    try {
      let responseText: string;
      
      if (this.debugMode && this.ollamaProvider) {
        // Mode debug : utiliser Ollama
        console.log('ü¶ô Analyse archiviste avec Ollama (mode debug)...');
        const ollamaResponse = await this.ollamaProvider.generateResponse(prompt, 1000);
        responseText = ollamaResponse.content || '';
        
        if (ollamaResponse.error) {
          console.warn('‚ö†Ô∏è Ollama archiviste √©chou√©, fallback vers Gemini...');
          if (this.model) {
            const result = await this.model.generateContent(prompt);
            responseText = result.response.text().trim();
          } else {
            throw new Error('Aucun provider disponible');
          }
        }
      } else {
        // Mode production : utiliser Gemini
        if (!this.model) {
          throw new Error('Mod√®le Gemini non initialis√©');
        }
        console.log('üîë Analyse archiviste avec Gemini (mode production)...');
        if (this.isVerbosePrompts()) {
          console.log('===== ARCHIVIST ANALYSIS PROMPT (FULL) =====');
          console.log(prompt);
          console.log('===== END PROMPT =====');
        }
        const result = await this.model.generateContent(prompt);
        responseText = result.response.text().trim();
        if (this.isVerboseOutputs()) {
          console.log('===== ARCHIVIST ANALYSIS RAW OUTPUT (FULL) =====');
          console.log(responseText);
          console.log('===== END OUTPUT =====');
        }
      }
      
      // Parsing JSON plus strict en mode debug
      let jsonText: string;
      if (this.debugMode) {
        // Mode debug : extraire le JSON des triple backticks (format naturel d'Ollama)
        const jsonMatch = responseText.match(/```json\s*([\s\S]*?)\s*```/);
        if (jsonMatch) {
          jsonText = jsonMatch[1].trim();
        } else {
          // Fallback : chercher le JSON entre accolades
          const fallbackMatch = responseText.match(/\{[\s\S]*\}/);
          if (fallbackMatch) {
            jsonText = fallbackMatch[0];
          } else {
            console.warn('‚ö†Ô∏è Aucun JSON trouv√© dans la r√©ponse Ollama debug');
            return this.simpleFallback(request);
          }
        }
      } else {
        // Mode production : parsing standard
        const jsonMatch = responseText.match(/\{[\s\S]*\}/);
        if (!jsonMatch) {
          throw new Error('R√©ponse JSON invalide');
        }
        jsonText = jsonMatch[0];
      }

      try {
        const parsed = JSON.parse(jsonText);
        
        // Validation stricte des champs requis
        const requiredFields = ['intent', 'suggestedTools', 'parameters', 'confidence', 'reasoning'];
        const missingFields = requiredFields.filter(field => !(field in parsed));
        
        if (missingFields.length > 0) {
          console.warn(`‚ö†Ô∏è JSON Ollama incomplet - champs manquants: ${missingFields.join(', ')}`);
          return this.simpleFallback(request);
        }
        
        if (!Array.isArray(parsed.suggestedTools)) {
          console.warn('‚ö†Ô∏è JSON Ollama invalide - suggestedTools n\'est pas un array');
          return this.simpleFallback(request);
        }
        
        if (typeof parsed.parameters !== 'object' || parsed.parameters === null) {
          console.warn('‚ö†Ô∏è JSON Ollama invalide - parameters n\'est pas un objet');
          return this.simpleFallback(request);
        }
        
        console.log('‚úÖ JSON Ollama valid√© avec succ√®s');
        return parsed;
        
      } catch (parseError) {
        console.warn('‚ö†Ô∏è Erreur parsing JSON Ollama:', parseError);
        return this.simpleFallback(request);
      }
    } catch (error) {
      console.error('‚ùå Erreur analyse personnalit√©:', error);
      // Fallback simple bas√© sur le contenu de la requ√™te
      return this.simpleFallback(request);
    }
  }

  /**
   * Cr√©e un prompt strict pour le mode debug (Ollama)
   */
  private createDebugPrompt(personalizedPrompt: string, request: string, context: any): string {
    return `${personalizedPrompt}

REQU√äTE √Ä ANALYSER: "${request}"
CONTEXTE: ${JSON.stringify(context, null, 2)}

T√ÇCHE: Analyse cette requ√™te et d√©termine quels outils utiliser et avec quels param√®tres.

IMPORTANT - MODE DEBUG:
- Tu dois r√©pondre UNIQUEMENT avec du JSON valide
- Pas de texte avant ou apr√®s le JSON
- Pas de markdown (triple backticks json)
- Le JSON doit √™tre complet et valide
- Utilise des guillemets doubles pour les strings
- Les arrays doivent √™tre entre crochets []
- Les objets doivent √™tre entre accolades {}
- Utilise UNIQUEMENT des guillemets doubles pour les strings JSON
- NE JAMAIS mettre de guillemets √† l'int√©rieur des valeurs
- Si une valeur contient des guillemets, supprime-les compl√®tement
- Exemple: {"request": "bonjour"} au lieu de {"request": "'bonjour'"}
- Pour la requ√™te, utilise seulement le mot principal sans guillemets
- Si la requ√™te est "Bonjour Algareth !", utilise "bonjour" dans le JSON

OUTILS DISPONIBLES:
- grep_chat_v2_semantic(request, includeImages?, includePrompts?)
- grep_conv(conv_id, request)
- list_convs(request?)
- grep_all_convs(request)

R√âPONDS UNIQUEMENT AVEC CE JSON EXACT (pas d'autre texte):
{
  "intent": "description_de_l_intention",
  "suggestedTools": ["grep_chat_v2_semantic"],
  "parameters": {
    "grep_chat_v2_semantic": {"request": "ta_requete_ici", "includeImages": false, "includePrompts": false}
  },
  "confidence": 0.8,
  "reasoning": "explication_de_la_strat√©gie"
}

EXEMPLES DE PARAM√àTRES CORRECTS:
- Pour grep_chat_v2_semantic: {"request": "recherche simple", "includeImages": false, "includePrompts": false}
- Pour grep_conv: {"conv_id": "conv-123", "request": "mot cle"}
- Pour list_convs: {"request": "filtre"}
- Pour grep_all_convs: {"request": "terme recherche"}

ATTENTION: Utilise des mots simples sans guillemets dans les valeurs !`;
  }

  /**
   * Cr√©e un prompt standard pour le mode production (Gemini)
   */
  private createProductionPrompt(personalizedPrompt: string, request: string, context: any): string {
    return `${personalizedPrompt}

REQU√äTE √Ä ANALYSER: "${request}"
CONTEXTE: ${JSON.stringify(context, null, 2)}

T√ÇCHE: Analyse cette requ√™te et d√©termine quels outils utiliser et avec quels param√®tres.

R√àGLES JSON STRICTES:
- Utilise UNIQUEMENT des guillemets doubles pour les strings JSON
- NE JAMAIS mettre de guillemets √† l'int√©rieur des valeurs
- Si une valeur contient des guillemets, supprime-les compl√®tement
- Exemple: {"request": "bonjour"} au lieu de {"request": "'bonjour'"}
- Pour la requ√™te, utilise seulement le mot principal sans guillemets

R√âPONDS UNIQUEMENT EN JSON avec cette structure exacte:
{
  "intent": "description_de_l_intention",
  "suggestedTools": ["tool1", "tool2"],
  "parameters": {
    "tool1": {"param1": "value1", "param2": "value2"},
    "tool2": {"param1": "value1"}
  },
  "confidence": 0.0-1.0,
  "reasoning": "explication_de_la_strat√©gie"
}

ATTENTION: Utilise des mots simples sans guillemets dans les valeurs !`;
  }

  /**
   * Fallback simple bas√© sur le contenu de la requ√™te
   */
  private simpleFallback(request: string): any {
    console.log('üîÑ Utilisation du fallback simple pour l\'archiviste');
    
    // Analyse simple bas√©e sur des mots-cl√©s
    const lowerRequest = request.toLowerCase();
    
    if (lowerRequest.includes('recherche') || lowerRequest.includes('trouve') || lowerRequest.includes('cherche')) {
      return {
        intent: "recherche_s√©mantique",
        suggestedTools: ["semantic_search"],
        parameters: {
          semantic_search: { query: request }
        },
        confidence: 0.7,
        reasoning: "Fallback: d√©tection de mots-cl√©s de recherche"
      };
    }
    
    if (lowerRequest.includes('sauvegarde') || lowerRequest.includes('enregistre') || lowerRequest.includes('stocke')) {
      return {
        intent: "sauvegarde_conversation",
        suggestedTools: ["save_conversation"],
        parameters: {
          save_conversation: { content: request }
        },
        confidence: 0.7,
        reasoning: "Fallback: d√©tection de mots-cl√©s de sauvegarde"
      };
    }
    
    // Fallback par d√©faut
    return {
      intent: "analyse_g√©n√©rale",
      suggestedTools: [],
      parameters: {},
      confidence: 0.3,
      reasoning: "Fallback: aucune action sp√©cifique d√©tect√©e"
    };
  }

  /**
   * D√©termine les outils n√©cessaires bas√©s sur l'analyse
   */
  private determineRequiredTools(analysis: any): ArchivistTool[] {
    const tools: ArchivistTool[] = [];
    
    for (const toolName of analysis.suggestedTools) {
      const tool = this.availableTools.get(toolName);
      if (tool) {
        tools.push(tool);
      } else {
        console.warn(`‚ö†Ô∏è Outil "${toolName}" non trouv√©`);
      }
    }
    
    return tools;
  }

  /**
   * Ex√©cute les outils avec auto-feedback loop
   */
  private async executeWithFeedbackLoop(
    tools: ArchivistTool[], 
    analysis: any, 
    context: any
  ): Promise<ToolResult[]> {
    return await this.executeWithDepth(tools, analysis, context);
  }

  /**
   * Ex√©cute avec profondeur contr√¥l√©e
   */
  private async executeWithDepth(
    tools: ArchivistTool[], 
    analysis: any, 
    context: any
  ): Promise<ToolResult[]> {
    if (this.currentDepth >= this.maxLoopDepth) {
      console.log(`üîÑ Auto-feedback loop atteint la profondeur maximale (${this.maxLoopDepth})`);
      return [];
    }

    this.currentDepth++;
    console.log(`üîÑ Auto-feedback loop - Profondeur: ${this.currentDepth}/${this.maxLoopDepth}`);

    const results: ToolResult[] = [];

    for (const tool of tools) {
      try {
        const params = analysis.parameters[tool.name] || {};
        const result = await tool.execute(params);
        results.push(result);

        // Auto-feedback : analyser si le r√©sultat est satisfaisant
        const isSatisfied = await this.evaluateResult(result, analysis);
        
        if (!isSatisfied && this.currentDepth < this.maxLoopDepth) {
          console.log(`üîÑ R√©sultat insatisfaisant, recherche d'outils suppl√©mentaires...`);
          
          // Sugg√©rer de nouveaux outils ou strat√©gies
          const additionalTools = await this.suggestAdditionalTools(result, analysis);
          if (additionalTools.length > 0) {
            const additionalResults = await this.executeWithDepth(additionalTools, analysis, context);
            results.push(...additionalResults);
          }
        }
      } catch (error) {
        console.error(`‚ùå Erreur ex√©cution outil ${tool.name}:`, error);
        results.push({
          success: false,
          error: `Erreur ex√©cution ${tool.name}: ${error}`,
          tool: tool.name,
          timestamp: new Date().toISOString()
        });
      }
    }

    return results;
  }

  /**
   * √âvalue si un r√©sultat est satisfaisant
   */
  private async evaluateResult(result: ToolResult, analysis: any): Promise<boolean> {
    if (!result.success) return false;
    
    const data = result.data;
    if (!data) return false;
    
    // Crit√®res d'√©valuation basiques
    if (Array.isArray(data) && data.length === 0) return false;
    if (typeof data === 'object' && Object.keys(data).length === 0) return false;
    
    // √âvaluation plus sophistiqu√©e
    return this.assessRelevance(data, analysis);
  }

  /**
   * √âvalue la pertinence des donn√©es
   */
  private assessRelevance(data: any, analysis: any): boolean {
    // Logique simple pour l'instant
    // Peut √™tre am√©lior√©e avec un LLM pour √©valuer la pertinence
    
    if (Array.isArray(data)) {
      return data.length > 0;
    }
    
    if (typeof data === 'object') {
      return Object.keys(data).length > 0;
    }
    
    return data && data.length > 0;
  }

  /**
   * Sugg√®re des outils suppl√©mentaires
   */
  private async suggestAdditionalTools(
    currentResult: ToolResult, 
    analysis: any
  ): Promise<ArchivistTool[]> {
    const suggestions: ArchivistTool[] = [];
    
    // Si grep_conv ne trouve rien, essayer grep_chat_v2_semantic (PRIORIT√â)
    if (currentResult.tool === 'grep_conv' && !currentResult.data?.results?.length) {
      const semanticTool = this.availableTools.get('grep_chat_v2_semantic');
      if (semanticTool) {
        console.log('üîÑ Auto-feedback: grep_conv vide ‚Üí suggestion grep_chat_v2_semantic');
        suggestions.push(semanticTool);
      }
    }
    
    // Si grep_all_convs ne trouve rien, essayer grep_chat_v2_semantic (PRIORIT√â)
    if (currentResult.tool === 'grep_all_convs' && !currentResult.data?.results?.length) {
      const semanticTool = this.availableTools.get('grep_chat_v2_semantic');
      if (semanticTool) {
        console.log('üîÑ Auto-feedback: grep_all_convs vide ‚Üí suggestion grep_chat_v2_semantic');
        suggestions.push(semanticTool);
      }
    }
    
    // Si les r√©sultats sont trop g√©n√©raux, affiner la recherche
    if (this.isResultTooGeneral(currentResult)) {
      const refinedTool = this.createRefinedSearchTool(analysis);
      if (refinedTool) {
        suggestions.push(refinedTool);
      }
    }
    
    return suggestions;
  }

  /**
   * V√©rifie si un r√©sultat est trop g√©n√©ral
   */
  private isResultTooGeneral(result: ToolResult): boolean {
    // Logique simple pour d√©tecter si les r√©sultats sont trop g√©n√©raux
    if (!result.success || !result.data) return false;
    
    const data = result.data;
    if (Array.isArray(data)) {
      return data.length > 10; // Trop de r√©sultats
    }
    
    return false;
  }

  /**
   * Cr√©e un outil de recherche affin√©e
   */
  private createRefinedSearchTool(analysis: any): ArchivistTool | null {
    // Pour l'instant, retourner null
    // Peut √™tre √©tendu pour cr√©er des outils dynamiques
    return null;
  }

  /**
   * Formate les r√©sultats pour le prompt en √©vitant les citations vides
   */
  private formatResultsForPrompt(results: ToolResult[]): string {
    const formattedResults = results.map(result => {
      if (!result.success || !result.data) {
        return `‚ùå ${result.tool}: ${result.error || '√âchec'}`;
      }

      const data = result.data;
      
      // Si c'est un r√©sultat de recherche s√©mantique avec des conversations
      if (data.semanticResults && data.semanticResults.actualConversations) {
        const conversations = data.semanticResults.actualConversations;
        const conversationTexts = conversations.map((conv: any, index: number) => {
          const speakerInfo = conv.speakerLabel 
            ? `${conv.speakerLabel} (${conv.speakerRole || 'inconnu'})`
            : (conv.speakerRole || 'inconnu');
          const content = conv.message || conv.userMessage || '';
          return `${index + 1}. Session: "${conv.sessionTitle}" (Score: ${conv.semanticScore?.toFixed(3) || 'N/A'})
   - Interlocuteur: ${speakerInfo}
   - Message: "${content}"
   - Timestamp: ${conv.timestamp}`;
        }).join('\n\n');
        
        return `${result.tool} (${conversations.length} conversations trouv√©es):
${conversationTexts}`;
      }
      
      // Pour les autres types de r√©sultats, utiliser JSON mais tronqu√©
      const jsonStr = JSON.stringify(data, null, 2);
      const truncatedJson = jsonStr.length > 1000 ? 
        jsonStr.substring(0, 1000) + '... [tronqu√©]' : 
        jsonStr;
        
      return `${result.tool}: ${truncatedJson}`;
    });

    return formattedResults.join('\n\n---\n\n');
  }

  /**
   * G√©n√®re la r√©ponse finale
   */
  private async generateFinalResponse(
    results: ToolResult[], 
    analysis: any, 
    originalRequest: string
  ): Promise<string> {
    // Remplacer [USER_NAME] par le vrai nom d'utilisateur
    const userName = this.currentContext?.userName || 'l\'utilisateur';
    const personalizedPrompt = this.personality.replace(/\[USER_NAME\]/g, userName);
    
    // Formater les r√©sultats pour √©viter les citations vides
    const formattedResults = this.formatResultsForPrompt(results);
    
    // Construire un √©ventuel bloc d'audit (Top N) si verbose total
    let auditBlock = '';
    if (this.getVerboseMode() === 'total') {
      const semanticTool = results.find(r => r.tool === 'grep_chat_v2_semantic' && r.success);
      const convs = semanticTool?.data?.semanticResults?.actualConversations || [];
      if (convs.length > 0) {
        const top = convs.slice(0, 5).map((c: any, i: number) => {
          return `${i + 1}. Score: ${(c.semanticScore ?? 0).toFixed(3)} | R√¥le: ${c.speakerRole || 'unknown'} | Session: ${c.sessionId || 'unknown'}\n   "${(c.userMessage || c.message || '').substring(0, 200)}${(c.userMessage || c.message || '').length > 200 ? '...' : ''}"`;
        }).join('\n');
        auditBlock = `\n\n[AUDIT ‚Äî Top r√©sultats s√©mantiques]\n${top}`;
      }
    }

    const prompt = `${personalizedPrompt}

ROLE: Tu es l'archiviste, tu viens d'ex√©cuter une recherche m√©moire sur les conversations entre Algareth et l'utilisateur. Tu n'es PAS Algareth, tu es son archiviste qui fouille dans les archives des conversations pass√©es.

REQU√äTE ORIGINALE: "${originalRequest}"
ANALYSE: ${JSON.stringify(analysis, null, 2)}
R√âSULTATS DES OUTILS: ${formattedResults}
${auditBlock}

T√ÇCHE: G√©n√®re une r√©ponse enthousiaste et professionnelle pour Algareth, en utilisant les r√©sultats des outils.

STYLE:
- Commence par "Salut Algareth, je suis l'archiviste"
- Sois enthousiaste et passionn√©
- Pr√©sente les informations de mani√®re organis√©e
- Termine par "Peut-√™tre pourront-elles t'aider √† mieux r√©pondre ?"
- Utilise des emojis appropri√©s (üìö, üîç, etc.)

IMPORTANT: 
- Ne mentionne pas les outils utilis√©s, pr√©sente juste les informations trouv√©es
- Si tu trouves des conversations sp√©cifiques, CITE-LEUR LE CONTENU R√âEL
- Ne donne pas seulement des m√©tadonn√©es (scores, nombres), mais cite les conversations trouv√©es
- Utilise le format: "Dans la conversation [titre], l'utilisateur ${userName} a dit: '[citation]' et Algareth a r√©pondu: '[citation]'"
- Sois pr√©cis et cite les passages pertinents pour r√©pondre √† la question
- Rappelle-toi: tu es l'archiviste qui rapporte les conversations pass√©es, pas Algareth lui-m√™me`;

    try {
      let responseText: string;
      
      if (this.debugMode && this.ollamaProvider) {
        // Mode debug : utiliser Ollama
        console.log('ü¶ô G√©n√©ration r√©ponse finale archiviste avec Ollama (mode debug)...');
        const ollamaResponse = await this.ollamaProvider.generateResponse(prompt, 1000);
        responseText = ollamaResponse.content || '';
        
        if (ollamaResponse.error) {
          console.warn('‚ö†Ô∏è Ollama archiviste √©chou√©, fallback vers Gemini...');
          if (this.model) {
            const result = await this.model.generateContent(prompt);
            responseText = result.response.text().trim();
          } else {
            throw new Error('Aucun provider disponible');
          }
        }
      } else {
        // Mode production : utiliser Gemini
        if (!this.model) {
          throw new Error('Mod√®le Gemini non initialis√©');
        }
        console.log('üîë G√©n√©ration r√©ponse finale archiviste avec Gemini (mode production)...');
        if (this.isVerbosePrompts()) {
          console.log('===== ARCHIVIST FINAL PROMPT (FULL) =====');
          console.log(prompt);
          console.log('===== END PROMPT =====');
        }
        const result = await this.model.generateContent(prompt);
        responseText = result.response.text().trim();
        if (this.isVerboseOutputs()) {
          console.log('===== ARCHIVIST FINAL RAW OUTPUT (FULL) =====');
          console.log(responseText);
          console.log('===== END OUTPUT =====');
        }
      }
      
      return responseText;
    } catch (error) {
      console.error('‚ùå Erreur g√©n√©ration r√©ponse finale:', error);
      return `Salut Algareth, je suis l'archiviste. J'ai fouill√© dans mes archives mais j'ai rencontr√© un probl√®me technique. Peut-√™tre l'utilisateur pourrait-il reformuler sa question ?`;
    }
  }

  // Impl√©mentations des outils

  /**
   * Ex√©cute grep_conv
   */
  private async executeGrepConv(params: { conv_id: string, request: string }): Promise<ToolResult> {
    try {
      console.log(`üîç grep_conv: ${params.conv_id} - "${params.request}"`);
      
      if (this.isWebMode) {
        // Mode web : utiliser l'API
        const response = await fetch('/api/conversations', {
          method: 'GET',
          headers: { 'Content-Type': 'application/json' }
        });
        
        if (!response.ok) {
          throw new Error(`API error: ${response.status}`);
        }
        
        const data = await response.json();
        const conversations = data.data.conversations;
        
        // Rechercher dans les conversations
        const results = conversations
          .filter((conv: any) => conv.id === params.conv_id)
          .flatMap((conv: any) => {
            const queryLower = params.request.toLowerCase();
            const matches = [];
            
            if (conv.message.toLowerCase().includes(queryLower)) {
              matches.push({
                conversationId: conv.id,
                conversationTitle: `Conversation ${conv.id}`,
                messageId: `msg_${conv.id}_user`,
                message: {
                  id: `msg_${conv.id}_user`,
                  role: 'user' as const,
                  content: conv.message,
                  timestamp: conv.timestamp
                },
                relevanceScore: 0.8,
                context: `Conversation ${conv.id}`
              });
            }
            
            if (conv.response.toLowerCase().includes(queryLower)) {
              matches.push({
                conversationId: conv.id,
                conversationTitle: `Conversation ${conv.id}`,
                messageId: `msg_${conv.id}_assistant`,
                message: {
                  id: `msg_${conv.id}_assistant`,
                  role: 'assistant' as const,
                  content: conv.response,
                  timestamp: conv.timestamp
                },
                relevanceScore: 0.8,
                context: `Conversation ${conv.id}`
              });
            }
            
            return matches;
          });

        return {
          success: true,
          data: {
            conversationId: params.conv_id,
            query: params.request,
            results: results,
            totalMatches: results.length
          },
          tool: 'grep_conv',
          timestamp: new Date().toISOString()
        };
      } else {
        // Mode fichier : utiliser la base de donn√©es
        const results = await this.conversationDatabase!.searchInConversation(params.conv_id, params.request);

        return {
          success: true,
          data: {
            conversationId: params.conv_id,
            query: params.request,
            results: results,
            totalMatches: results.length
          },
          tool: 'grep_conv',
          timestamp: new Date().toISOString()
        };
      }
    } catch (error) {
      return {
        success: false,
        error: `Erreur grep_conv: ${error}`,
        tool: 'grep_conv',
        timestamp: new Date().toISOString()
      };
    }
  }

  /**
   * Ex√©cute list_convs
   */
  private async executeListConvs(params: { request?: string }): Promise<ToolResult> {
    try {
      console.log(`üìã list_convs: "${params.request || 'toutes'}"`);
      
      if (this.isWebMode) {
        // Mode web : utiliser le syst√®me de sessions (comme le fait le chat)
        const { LocalSessionStorage } = await import('@/lib/sessions/SessionStorage');
        const sessionStorage = new LocalSessionStorage();
        
        // Trouver tous les utilisateurs qui ont des sessions
        const allKeys = Object.keys(localStorage);
        const sessionKeys = allKeys.filter(key => key.startsWith('lr_tchatagent_sessions_'));
        const users = sessionKeys.map(key => key.replace('lr_tchatagent_sessions_', ''));
        
        console.log(`üìã Archiviste: ${users.length} utilisateurs trouv√©s pour list_convs`);
        
        const conversations = [];
        
        for (const user of users) {
          const sessions = await sessionStorage.loadSessions(user);
          console.log(`üìÇ Archiviste: ${sessions.length} sessions trouv√©es pour ${user}`);
          
          for (const session of sessions) {
            const sessionMemory = await sessionStorage.loadSessionMemory(session.id);
            if (sessionMemory && sessionMemory.messages) {
              // Convertir les messages en conversations
              for (let i = 0; i < sessionMemory.messages.length; i += 2) {
                const userMessage = sessionMemory.messages[i];
                const assistantMessage = sessionMemory.messages[i + 1];
                
                if (userMessage && assistantMessage) {
                  conversations.push({
                    id: `${session.id}_${i}`,
                    user: user,
                    message: userMessage.content,
                    response: assistantMessage.content,
                    timestamp: userMessage.timestamp,
                    metadata: {
                      sessionId: session.id,
                      sessionTitle: session.title
                    }
                  });
                }
              }
            }
          }
        }
        
        console.log(`üìã Archiviste: ${conversations.length} conversations charg√©es depuis les sessions`);
        
        // Logs d√©taill√©s des conversations charg√©es
        console.log(`üìä D√©tails des conversations charg√©es:`);
        conversations.forEach((conv: any, index: number) => {
          console.log(`   ${index + 1}. ID: ${conv.id} | Utilisateur: ${conv.user} | Session: ${conv.metadata.sessionId}`);
          console.log(`      Titre session: "${conv.metadata.sessionTitle}"`);
          console.log(`      Message: "${conv.message.substring(0, 80)}${conv.message.length > 80 ? '...' : ''}"`);
          console.log(`      R√©ponse: "${conv.response.substring(0, 80)}${conv.response.length > 80 ? '...' : ''}"`);
          console.log(`      Timestamp: ${conv.timestamp}`);
        });
        
        // Filtrer si une requ√™te est fournie
        const filtered = params.request ? 
          conversations.filter((conv: any) => 
            conv.message.toLowerCase().includes(params.request!.toLowerCase()) ||
            conv.response.toLowerCase().includes(params.request!.toLowerCase())
          ) :
          conversations;

        return {
          success: true,
          data: {
            conversations: filtered.map((conv: any) => ({
              id: conv.id,
              title: `Conversation ${conv.id}`,
              userId: conv.user,
              createdAt: conv.timestamp,
              messageCount: 1 // Chaque entr√©e repr√©sente un √©change
            })),
            totalCount: filtered.length,
            filter: params.request
          },
          tool: 'list_convs',
          timestamp: new Date().toISOString()
        };
      } else {
        // Mode fichier : utiliser la base de donn√©es
        if (!this.currentContext?.userIdentityId) {
          throw new Error('Contexte utilisateur manquant pour r√©cup√©rer les conversations');
        }
        
        const conversations = await this.conversationDatabase!.getAllConversations(this.currentContext.userIdentityId);
        
        // Filtrer si une requ√™te est fournie
        const filtered = params.request ? 
          conversations.filter(conv => 
            conv.title.toLowerCase().includes(params.request!.toLowerCase()) ||
            conv.messages.some(msg => msg.content.toLowerCase().includes(params.request!.toLowerCase()))
          ) :
          conversations;

        return {
          success: true,
          data: {
            conversations: filtered.map(conv => ({
              id: conv.id,
              title: conv.title,
              userId: conv.userId,
              createdAt: conv.createdAt,
              messageCount: conv.messages.length
            })),
            totalCount: filtered.length,
            filter: params.request
          },
          tool: 'list_convs',
          timestamp: new Date().toISOString()
        };
      }
    } catch (error) {
      return {
        success: false,
        error: `Erreur list_convs: ${error}`,
        tool: 'list_convs',
        timestamp: new Date().toISOString()
      };
    }
  }

  /**
   * Ex√©cute grep_all_convs
   */
  private async executeGrepAllConvs(params: { request: string }): Promise<ToolResult> {
    try {
      console.log(`üîç grep_all_convs: "${params.request}"`);
      
      if (this.isWebMode) {
        // Mode web : utiliser le syst√®me de sessions (comme le fait le chat)
        const { LocalSessionStorage } = await import('@/lib/sessions/SessionStorage');
        const sessionStorage = new LocalSessionStorage();
        
        // Trouver tous les utilisateurs qui ont des sessions
        const allKeys = Object.keys(localStorage);
        const sessionKeys = allKeys.filter(key => key.startsWith('lr_tchatagent_sessions_'));
        const users = sessionKeys.map(key => key.replace('lr_tchatagent_sessions_', ''));
        
        console.log(`üîç Archiviste: ${users.length} utilisateurs trouv√©s pour recherche`);
        console.log(`üîç Cl√©s localStorage:`, allKeys.filter(key => key.includes('session')));
        console.log(`üîç Utilisateurs:`, users);
        
        // Debug d√©taill√© des sessions
        sessionKeys.forEach(key => {
          const data = localStorage.getItem(key);
          try {
            const parsed = JSON.parse(data);
            console.log(`üìÇ Archiviste voit ${key}:`, typeof parsed, Array.isArray(parsed) ? `${parsed.length} sessions` : 'donn√©es');
            if (Array.isArray(parsed) && parsed.length > 0) {
              console.log(`   Premi√®re session:`, parsed[0].id, parsed[0].title);
            }
          } catch (e) {
            console.log(`üìÇ Archiviste voit ${key}: donn√©es non-JSON`);
          }
        });
        
        const conversations = [];
        
        for (const user of users) {
          const sessions = await sessionStorage.loadSessions(user);
          console.log(`üìÇ Archiviste: ${sessions.length} sessions trouv√©es pour ${user}`);
          
          for (const session of sessions) {
            const sessionMemory = await sessionStorage.loadSessionMemory(session.id);
            if (sessionMemory && sessionMemory.messages) {
              // Convertir les messages en conversations
              for (let i = 0; i < sessionMemory.messages.length; i += 2) {
                const userMessage = sessionMemory.messages[i];
                const assistantMessage = sessionMemory.messages[i + 1];
                
                if (userMessage && assistantMessage) {
                  conversations.push({
                    id: `${session.id}_${i}`,
                    user: user,
                    message: userMessage.content,
                    response: assistantMessage.content,
                    timestamp: userMessage.timestamp,
                    metadata: {
                      sessionId: session.id,
                      sessionTitle: session.title
                    }
                  });
                }
              }
            }
          }
        }
        
        console.log(`üîç Archiviste: ${conversations.length} conversations charg√©es depuis les sessions`);
        
        // Logs d√©taill√©s des conversations charg√©es pour grep_all_convs
        console.log(`üìä D√©tails des conversations charg√©es (grep_all_convs):`);
        conversations.forEach((conv: any, index: number) => {
          console.log(`   ${index + 1}. ID: ${conv.id} | Utilisateur: ${conv.user} | Session: ${conv.metadata.sessionId}`);
          console.log(`      Titre session: "${conv.metadata.sessionTitle}"`);
          console.log(`      Message: "${conv.message.substring(0, 80)}${conv.message.length > 80 ? '...' : ''}"`);
          console.log(`      R√©ponse: "${conv.response.substring(0, 80)}${conv.response.length > 80 ? '...' : ''}"`);
          console.log(`      Timestamp: ${conv.timestamp}`);
        });
        
        // Rechercher dans toutes les conversations
        const queryLower = params.request.toLowerCase();
        const results = conversations.flatMap((conv: any) => {
          const matches = [];
          
          if (conv.message.toLowerCase().includes(queryLower)) {
            matches.push({
              conversationId: conv.id,
              conversationTitle: `Conversation ${conv.id}`,
              messageId: `msg_${conv.id}_user`,
              message: {
                id: `msg_${conv.id}_user`,
                role: 'user' as const,
                content: conv.message,
                timestamp: conv.timestamp
              },
              relevanceScore: 0.8,
              context: `Conversation ${conv.id}`
            });
          }
          
          if (conv.response.toLowerCase().includes(queryLower)) {
            matches.push({
              conversationId: conv.id,
              conversationTitle: `Conversation ${conv.id}`,
              messageId: `msg_${conv.id}_assistant`,
              message: {
                id: `msg_${conv.id}_assistant`,
                role: 'assistant' as const,
                content: conv.response,
                timestamp: conv.timestamp
              },
              relevanceScore: 0.8,
              context: `Conversation ${conv.id}`
            });
          }
          
          return matches;
        });

        // Logs d√©taill√©s des r√©sultats de recherche
        console.log(`üìä R√©sultats de recherche grep_all_convs:`);
        console.log(`   üîç Requ√™te: "${params.request}"`);
        console.log(`   üìù Conversations recherch√©es: ${conversations.length}`);
        console.log(`   ‚úÖ R√©sultats trouv√©s: ${results.length}`);
        results.forEach((result, index) => {
          console.log(`   ${index + 1}. Conversation: ${result.conversationId} | Message ID: ${result.messageId}`);
          console.log(`      R√¥le: ${result.message.role} | Score: ${result.relevanceScore}`);
          console.log(`      Contenu: "${result.message.content.substring(0, 100)}${result.message.content.length > 100 ? '...' : ''}"`);
          console.log(`      Timestamp: ${result.message.timestamp}`);
        });

        return {
          success: true,
          data: {
            query: params.request,
            results: results,
            totalMatches: results.length,
            conversationsSearched: conversations.length
          },
          tool: 'grep_all_convs',
          timestamp: new Date().toISOString()
        };
      } else {
        // Mode fichier : utiliser la base de donn√©es
        // V√©rifier que le contexte utilisateur est disponible
        if (!this.currentContext?.userIdentityId) {
          throw new Error('Contexte utilisateur manquant pour la recherche dans les conversations');
        }
        
        const results = await this.conversationDatabase!.searchInAllConversations(params.request, this.currentContext.userIdentityId);
        const conversations = await this.conversationDatabase!.getAllConversations(this.currentContext.userIdentityId);

        return {
          success: true,
          data: {
            query: params.request,
            results: results,
            totalMatches: results.length,
            conversationsSearched: conversations.length
          },
          tool: 'grep_all_convs',
          timestamp: new Date().toISOString()
        };
      }
    } catch (error) {
      return {
        success: false,
        error: `Erreur grep_all_convs: ${error}`,
        tool: 'grep_all_convs',
        timestamp: new Date().toISOString()
      };
    }
  }

  /**
   * Ex√©cute grep_chat_v2_semantic - Recherche s√©mantique sp√©cialis√©e pour Chat V2
   */
  private async executeGrepChatV2Semantic(params: { 
    request: string; 
    includeImages?: boolean; 
    includePrompts?: boolean; 
  }): Promise<ToolResult> {
    try {
      console.log(`üîç grep_chat_v2_semantic: "${params.request}"`);
      console.log(`üìä Options: images=${params.includeImages}, prompts=${params.includePrompts}`);
      
      if (this.semanticSearchService) {
        // Utiliser le service de recherche s√©mantique (toujours, m√™me en debug)
        console.log(`üîç Archiviste Chat V2: Utilisation du service de recherche s√©mantique`);
        
        try {
          // V√©rifier que le contexte utilisateur est disponible
          if (!this.currentContext?.userIdentityId) {
            throw new Error('Contexte utilisateur manquant pour la recherche s√©mantique');
          }
          
          const userId = this.currentContext.userIdentityId;
          console.log(`üîç Archiviste Chat V2: Recherche pour utilisateur "${userId}"`);
          
          // Extraire le terme de recherche principal de la requ√™te complexe
          let searchQuery = params.request;
          console.log(`üîç Requ√™te brute re√ßue: "${searchQuery}"`);
          
          // Si la requ√™te contient des filtres SQL, extraire le terme principal
          if (searchQuery.includes(' AND ') || searchQuery.includes(' user_id:') || searchQuery.includes(' session_id:')) {
            // Extraire le terme entre guillemets ou le premier mot significatif
            const quotedMatch = searchQuery.match(/"([^"]+)"/);
            if (quotedMatch) {
              searchQuery = quotedMatch[1];
              console.log(`üîç Terme extrait des guillemets doubles: "${searchQuery}"`);
            } else {
              // Prendre le premier mot avant les filtres
              const firstWord = searchQuery.split(' ')[0];
              searchQuery = firstWord.replace(/[^a-zA-Z0-9]/g, '');
              console.log(`üîç Terme extrait (premier mot): "${searchQuery}"`);
            }
          }
          
          // Nettoyer les guillemets simples qui peuvent rester (fallback si le prompt ne fonctionne pas)
          if (searchQuery.startsWith("'") && searchQuery.endsWith("'")) {
            searchQuery = searchQuery.slice(1, -1);
            console.log(`üîç Guillemets simples supprim√©s (fallback): "${searchQuery}"`);
          }
          
          // Pas de substitutions en dur; on confie l'intention au LLM et √† la recherche s√©mantique
          
          console.log(`üîç Requ√™te s√©mantique finale: "${searchQuery}"`);
          console.log(`üîç Param√®tres de recherche: userIdentityId="${userId}", threshold=0.3, maxResults=10`);
          
          const results = await this.semanticSearchService.searchMessages(searchQuery, {
            similarityThreshold: 0.5, // plus strict; fallback √† 0.3 g√©r√© au niveau service
            maxResults: 10,
            userId: userId,
            authUserId: this.currentContext?.authUserId,
            embeddingProvider: 'gemini', // Utiliser Gemini pour 768 dimensions
            role: 'both',
            rolePriority: 'userFirst'
          });
          
          console.log(`üîç Archiviste Chat V2: ${results.length} r√©sultats s√©mantiques trouv√©s`);
          
          // Logs d√©taill√©s des r√©sultats bruts
          const verboseTotal = this.getVerboseMode() === 'total';
          if (this.isDebug() || verboseTotal) {
            console.log(`üìä R√©sultats bruts de la recherche s√©mantique:`);
            results.forEach((result, index) => {
              console.log(`   ${index + 1}. Score: ${result.similarity.toFixed(3)} | Session: ${result.metadata.sessionId || 'undefined'} | R√¥le: ${result.metadata.role || 'undefined'}`);
              const full = this.getVerboseMode() === 'total';
              const content = full ? result.content : `${result.content.substring(0, 100)}${result.content.length > 100 ? '...' : ''}`;
              console.log(`      Contenu: "${content}"`);
              console.log(`      Timestamp: ${result.metadata.timestamp || 'undefined'}`);
            });
            // Top N consolid√©
            const topN = results.slice(0, 5).map((r, i) => ({
              rank: i + 1,
              score: r.similarity.toFixed(3),
              role: r.metadata.role || 'unknown',
              session: r.metadata.sessionId || 'unknown',
              excerpt: r.content.substring(0, 160)
            }));
            console.log('üîù Top r√©sultats (score, role, session):');
            console.table(topN);
          }
          
          // Convertir les r√©sultats en format attendu (messages utilisateur prioris√©s)
          const semanticResults = {
            actualConversations: results.map(result => {
              const role = (result.metadata.role as 'user' | 'assistant') || 'user';
              const speakerLabel = role === 'user'
                ? (this.currentContext?.userName || this.currentContext?.userId || 'utilisateur')
                : this.getAssistantPersonaName();

              return {
                sessionTitle: result.metadata.sessionTitle || 
                             (result.metadata.sessionId ? `Session ${result.metadata.sessionId.substring(0, 8)}` : 'Session inconnue'),
                sessionId: result.metadata.sessionId || 'unknown',
                message: result.content,
                speakerRole: role,
                speakerLabel,
                context: `Message de ${speakerLabel}`,
                semanticScore: result.similarity,
                timestamp: result.metadata.timestamp || new Date().toISOString()
              };
            }),
            summary: `Recherche s√©mantique r√©ussie pour "${params.request}". ${results.length} conversations sp√©cifiques identifi√©es.`
          };
          
          return {
            success: true,
            data: {
              query: params.request,
              semanticResults: semanticResults,
              totalMatches: results.length,
              analysis: {
                geminiPromptsFound: 0,
                imageGenerationsFound: 0,
                contextInsights: [`Recherche s√©mantique dans PostgreSQL: ${results.length} r√©sultats`]
              }
            },
            tool: 'grep_chat_v2_semantic',
            timestamp: new Date().toISOString()
          };
        } catch (error) {
          console.error('‚ùå Erreur recherche s√©mantique:', error);
          return {
            success: false,
            error: `Erreur recherche s√©mantique: ${error}`,
            tool: 'grep_chat_v2_semantic',
            timestamp: new Date().toISOString()
          };
        }
      } else {
        // Mode fichier : utiliser la base de donn√©es avec recherche s√©mantique
        if (!this.conversationDatabase) {
          throw new Error('Base de donn√©es de conversations non initialis√©e');
        }
        
        // V√©rifier que le contexte utilisateur est disponible
        if (!this.currentContext?.userIdentityId) {
          throw new Error('Contexte utilisateur manquant pour la recherche dans les conversations');
        }
        
        const results = await this.conversationDatabase.searchInAllConversations(params.request, this.currentContext.userIdentityId);
        
        return {
          success: true,
          data: {
            query: params.request,
            results: results,
            totalMatches: results.length,
            note: 'Recherche s√©mantique en mode fichier'
          },
          tool: 'grep_chat_v2_semantic',
          timestamp: new Date().toISOString()
        };
      }
    } catch (error) {
      return {
        success: false,
        error: `Erreur grep_chat_v2_semantic: ${error}`,
        tool: 'grep_chat_v2_semantic',
        timestamp: new Date().toISOString()
      };
    }
  }

  /**
   * Effectue une recherche s√©mantique dans les messages Chat V2
   */
  private async performSemanticSearch(
    messages: any[], 
    query: string, 
    context: {
      sessionId: string;
      sessionTitle: string;
      user: string;
      includeImages: boolean;
      includePrompts: boolean;
    }
  ): Promise<any[]> {
    const queryLower = query.toLowerCase();
    const semanticMatches = [];
    
    for (let i = 0; i < messages.length; i++) {
      const message = messages[i];
      const content = message.content.toLowerCase();
      
      // Recherche s√©mantique √©tendue
      const semanticScore = await this.calculateSemanticScore(content, queryLower);
      
      if (semanticScore > 0.3) { // Seuil de pertinence
        const match = {
          sessionId: context.sessionId,
          sessionTitle: context.sessionTitle,
          user: context.user,
          messageId: message.id,
          message: message,
          semanticScore: semanticScore,
          context: this.extractContext(messages, i),
          timestamp: message.timestamp
        };
        
        // Extraire les informations sp√©cifiques si demand√©es
        if (context.includeImages && message.divineMurmurs) {
          match.imageData = this.extractImageData(message.divineMurmurs);
        }
        
        if (context.includePrompts && message.divineMurmurs) {
          match.promptData = this.extractPromptData(message.divineMurmurs);
        }
        
        semanticMatches.push(match);
      }
    }
    
    return semanticMatches.sort((a, b) => b.semanticScore - a.semanticScore);
  }

  /**
   * Calcule un score s√©mantique entre le contenu et la requ√™te
   * NOUVEAU: Utilise la vraie recherche s√©mantique avec embeddings
   */
  private async calculateSemanticScore(content: string, query: string): Promise<number> {
    // Si le service de recherche s√©mantique est disponible, l'utiliser
    if (this.semanticSearchService) {
      try {
        // Utiliser la recherche s√©mantique pour calculer la similarit√©
        const results = await this.semanticSearchService.searchMessages(query, {
          similarityThreshold: 0.1,
          maxResults: 1
        });
        
        // Si on trouve un r√©sultat exact, retourner sa similarit√©
        const exactMatch = results.find(result => result.content === content);
        if (exactMatch) {
          return exactMatch.similarity;
        }
        
        // Sinon, utiliser la recherche hybride pour une estimation
        const hybridResults = await this.semanticSearchService.hybridSearchMessages(query, {
          similarityThreshold: 0.1,
          maxResults: 5
        });
        
        // Trouver le meilleur match
        const bestMatch = hybridResults.find(result => 
          result.content.toLowerCase().includes(content.toLowerCase().substring(0, 50))
        );
        
        if (bestMatch) {
          return bestMatch.similarity;
        }
        
        // Fallback: utiliser la recherche par mots-cl√©s
        return this.calculateKeywordScore(content, query);
        
      } catch (error) {
        console.warn('‚ö†Ô∏è Erreur recherche s√©mantique, fallback vers mots-cl√©s:', error);
        return this.calculateKeywordScore(content, query);
      }
    }
    
    // Fallback vers l'ancienne m√©thode si pas de service s√©mantique
    return this.calculateKeywordScore(content, query);
  }
  
  /**
   * Ancienne m√©thode de scoring par mots-cl√©s (fallback)
   */
  private calculateKeywordScore(content: string, query: string): number {
    // Mots-cl√©s s√©mantiques pour Chat V2
    const semanticKeywords = {
      'gemini': ['gemini', 'image', 'g√©n√©ration', 'prompt', 'cr√©ation'],
      'image': ['image', 'dessin', 'cr√©er', 'montre', 'visuel', 'banane', 'd√©moniaque'],
      'probl√®me': ['probl√®me', 'bug', 'erreur', 'ne marche pas', 'ne fonctionne pas'],
      'timer': ['timer', 'chargement', 'dispara√Æt', 'loading'],
      'orchestrateur': ['orchestrateur', 'divin', 'luciole', 'murmure'],
      'archiviste': ['archiviste', 'm√©moire', 'souvenir', 'archive']
    };
    
    let score = 0;
    const queryWords = query.split(' ');
    
    // Score bas√© sur les mots-cl√©s s√©mantiques
    for (const [category, keywords] of Object.entries(semanticKeywords)) {
      const categoryScore = keywords.reduce((catScore, keyword) => {
        if (content.includes(keyword) && queryWords.some(word => word.includes(keyword))) {
          return catScore + 0.3;
        }
        return catScore;
      }, 0);
      score += categoryScore;
    }
    
    // Score bas√© sur la correspondance directe
    const directMatches = queryWords.filter(word => content.includes(word)).length;
    score += directMatches * 0.2;
    
    // Score bas√© sur la proximit√© des mots
    const proximityScore = this.calculateProximityScore(content, queryWords);
    score += proximityScore * 0.1;
    
    return Math.min(score, 1.0); // Normaliser entre 0 et 1
  }

  /**
   * Calcule un score de proximit√© entre les mots
   */
  private calculateProximityScore(content: string, queryWords: string[]): number {
    // Impl√©mentation simple : compter les mots de la requ√™te pr√©sents
    const contentWords = content.split(' ');
    const matches = queryWords.filter(word => 
      contentWords.some(contentWord => contentWord.includes(word))
    );
    return matches.length / queryWords.length;
  }

  /**
   * Extrait le contexte autour d'un message
   */
  private extractContext(messages: any[], index: number): string {
    const start = Math.max(0, index - 2);
    const end = Math.min(messages.length, index + 3);
    const contextMessages = messages.slice(start, end);
    
    return contextMessages.map((msg, i) => {
      const role = msg.role === 'user' ? 'Utilisateur' : 'Algareth';
      const marker = i === (index - start) ? '>>> ' : '';
      return `${marker}${role}: ${msg.content.substring(0, 100)}...`;
    }).join('\n');
  }

  /**
   * Extrait les donn√©es d'images des murmures divins
   */
  private extractImageData(divineMurmurs: any[]): any[] {
    return divineMurmurs
      .filter(murmur => murmur.type === 'image' || murmur.type === 'both')
      .map(murmur => ({
        type: murmur.type,
        content: murmur.content,
        imageUrl: murmur.data?.image?.url,
        enhancedPrompt: murmur.data?.enhancedPrompt,
        improvements: murmur.data?.improvements,
        timestamp: murmur.timestamp
      }));
  }

  /**
   * Extrait les donn√©es de prompts des murmures divins
   */
  private extractPromptData(divineMurmurs: any[]): any[] {
    return divineMurmurs
      .filter(murmur => murmur.type === 'memory' || murmur.type === 'both')
      .map(murmur => ({
        type: murmur.type,
        content: murmur.content,
        archivistResponse: murmur.data,
        timestamp: murmur.timestamp
      }));
  }

  /**
   * Analyse les r√©sultats Chat V2 pour extraire des insights
   */
  private async analyzeChatV2Results(results: any[], query: string): Promise<any> {
    const analysis = {
      geminiPrompts: [],
      imageGenerations: [],
      contextInsights: [],
      actualConversations: [], // NOUVEAU: citations r√©elles des conversations
      summary: ''
    };
    
    // Extraire les prompts Gemini
    results.forEach(result => {
      if (result.promptData) {
        analysis.geminiPrompts.push(...result.promptData);
      }
      if (result.imageData) {
        analysis.imageGenerations.push(...result.imageData);
      }
      
      // NOUVEAU: Extraire les citations r√©elles des conversations
      if (result.message && result.context) {
        analysis.actualConversations.push({
          sessionTitle: result.sessionTitle,
          sessionId: result.sessionId,
          userMessage: result.message.content,
          context: result.context,
          semanticScore: result.semanticScore,
          timestamp: result.timestamp
        });
      }
    });
    
    // G√©n√©rer des insights contextuels
    if (results.length > 0) {
      analysis.contextInsights = [
        `Trouv√© ${results.length} correspondances s√©mantiques dans Chat V2`,
        `Sessions analys√©es: ${new Set(results.map(r => r.sessionId)).size}`,
        `Utilisateurs concern√©s: ${new Set(results.map(r => r.user)).size}`,
        `Score moyen de pertinence: ${(results.reduce((sum, r) => sum + r.semanticScore, 0) / results.length).toFixed(2)}`
      ];
      
      analysis.summary = `Recherche s√©mantique r√©ussie pour "${query}". ${analysis.geminiPrompts.length} prompts Gemini et ${analysis.imageGenerations.length} g√©n√©rations d'images trouv√©es dans les sessions Chat V2. ${analysis.actualConversations.length} conversations sp√©cifiques identifi√©es.`;
    } else {
      analysis.summary = `Aucune correspondance s√©mantique trouv√©e pour "${query}" dans les sessions Chat V2.`;
    }
    
    return analysis;
  }

  /**
   * Teste l'agent archiviste
   */
  async testArchivist(): Promise<void> {
    console.log('üß™ Test PersonalityArchivistAgent');
    
    const testRequest = "Tu te souviens de mes pr√©f√©rences en couleurs ?";
    const context = {
      userId: 'test-user-id', // Utiliser un ID de test g√©n√©rique
      userName: 'Test User',
      currentSession: 'test_session'
    };

    try {
      const response = await this.processRequest(testRequest, context);
      console.log(`‚úÖ Test archiviste: ${response.success ? 'SUCCESS' : 'FAILED'}`);
      console.log(`üìù R√©ponse: ${response.message.substring(0, 200)}...`);
      console.log(`üîß Outils utilis√©s: ${response.toolsUsed.join(', ')}`);
      console.log(`üîÑ Boucles de feedback: ${response.feedbackLoops}`);
    } catch (error) {
      console.error('‚ùå Erreur test archiviste:', error);
    }
  }
}
