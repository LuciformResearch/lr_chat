/**
 * PerformanceProfiler - Syst√®me de mesure de performance
 * 
 * Mesure pr√©cis√©ment les op√©rations lourdes et g√©n√®re des artefacts de performance
 */

export interface PerformanceMetrics {
  operation: string;
  startTime: number;
  endTime: number;
  duration: number;
  memoryUsage: number;
  llmCalls: number;
  details: Record<string, any>;
}

export interface PerformanceReport {
  totalDuration: number;
  operations: PerformanceMetrics[];
  bottlenecks: Bottleneck[];
  recommendations: string[];
  summary: {
    totalOperations: number;
    totalLLMCalls: number;
    averageDuration: number;
    memoryPeak: number;
  };
}

export interface Bottleneck {
  operation: string;
  duration: number;
  percentage: number;
  recommendation: string;
}

export class PerformanceProfiler {
  private metrics: PerformanceMetrics[] = [];
  private currentOperation: string | null = null;
  private startTime: number = 0;
  private llmCallCount: number = 0;

  /**
   * D√©marre une op√©ration
   */
  startOperation(operation: string): void {
    if (this.currentOperation) {
      console.warn(`‚ö†Ô∏è  Op√©ration ${this.currentOperation} non termin√©e, d√©marrage de ${operation}`);
    }
    
    this.currentOperation = operation;
    this.startTime = performance.now();
    
    console.log(`üîÑ D√©but: ${operation}`);
  }

  /**
   * Termine une op√©ration
   */
  endOperation(): PerformanceMetrics {
    if (!this.currentOperation) {
      throw new Error('Aucune op√©ration en cours');
    }
    
    const endTime = performance.now();
    const duration = endTime - this.startTime;
    const memoryUsage = process.memoryUsage().heapUsed;
    
    const metric: PerformanceMetrics = {
      operation: this.currentOperation,
      startTime: this.startTime,
      endTime,
      duration,
      memoryUsage,
      llmCalls: 0,
      details: {}
    };
    
    this.metrics.push(metric);
    
    console.log(`‚úÖ Fin: ${this.currentOperation} (${duration.toFixed(2)}ms)`);
    
    this.currentOperation = null;
    return metric;
  }

  /**
   * Enregistre un appel LLM
   */
  recordLLMCall(operation: string, details: Record<string, any> = {}): void {
    this.llmCallCount++;
    
    // Trouver l'op√©ration en cours ou la derni√®re
    let targetMetric: PerformanceMetrics | undefined;
    
    if (this.currentOperation === operation) {
      targetMetric = this.metrics[this.metrics.length - 1];
    } else {
      targetMetric = this.metrics.find(m => m.operation === operation);
    }
    
    if (targetMetric) {
      targetMetric.llmCalls++;
      targetMetric.details = { ...targetMetric.details, ...details };
    }
    
    console.log(`ü§ñ Appel LLM: ${operation} (total: ${this.llmCallCount})`);
  }

  /**
   * G√©n√®re le rapport de performance
   */
  getReport(): PerformanceReport {
    const totalDuration = this.metrics.reduce((sum, m) => sum + m.duration, 0);
    const totalLLMCalls = this.metrics.reduce((sum, m) => sum + m.llmCalls, 0);
    const averageDuration = totalDuration / this.metrics.length;
    const memoryPeak = Math.max(...this.metrics.map(m => m.memoryUsage));
    
    const bottlenecks = this.identifyBottlenecks(totalDuration);
    const recommendations = this.generateRecommendations(bottlenecks);
    
    return {
      totalDuration,
      operations: this.metrics,
      bottlenecks,
      recommendations,
      summary: {
        totalOperations: this.metrics.length,
        totalLLMCalls,
        averageDuration,
        memoryPeak
      }
    };
  }

  /**
   * Identifie les goulots d'√©tranglement
   */
  private identifyBottlenecks(totalDuration: number): Bottleneck[] {
    return this.metrics
      .map(metric => ({
        operation: metric.operation,
        duration: metric.duration,
        percentage: (metric.duration / totalDuration) * 100,
        recommendation: this.getRecommendation(metric)
      }))
      .sort((a, b) => b.duration - a.duration)
      .slice(0, 5); // Top 5 des goulots d'√©tranglement
  }

  /**
   * G√©n√®re des recommandations
   */
  private generateRecommendations(bottlenecks: Bottleneck[]): string[] {
    const recommendations: string[] = [];
    
    for (const bottleneck of bottlenecks) {
      if (bottleneck.percentage > 50) {
        recommendations.push(`üö® CRITIQUE: ${bottleneck.operation} repr√©sente ${bottleneck.percentage.toFixed(1)}% du temps total`);
      } else if (bottleneck.percentage > 20) {
        recommendations.push(`‚ö†Ô∏è  IMPORTANT: ${bottleneck.operation} repr√©sente ${bottleneck.percentage.toFixed(1)}% du temps total`);
      }
      
      recommendations.push(bottleneck.recommendation);
    }
    
    // Recommandations g√©n√©rales
    const llmOperations = this.metrics.filter(m => m.llmCalls > 0);
    if (llmOperations.length > 0) {
      const totalLLMTime = llmOperations.reduce((sum, m) => sum + m.duration, 0);
      const llmPercentage = (totalLLMTime / this.metrics.reduce((sum, m) => sum + m.duration, 0)) * 100;
      
      if (llmPercentage > 80) {
        recommendations.push('üí° OPTIMISATION: 80%+ du temps consacr√© aux appels LLM - consid√©rer le cache ou le mode test');
      }
    }
    
    return recommendations;
  }

  /**
   * G√©n√®re une recommandation pour une m√©trique
   */
  private getRecommendation(metric: PerformanceMetrics): string {
    if (metric.llmCalls > 0) {
      if (metric.duration > 5000) {
        return `üí° OPTIMISATION: ${metric.operation} prend ${metric.duration.toFixed(0)}ms - consid√©rer le cache ou l'optimisation du prompt`;
      } else if (metric.duration > 2000) {
        return `‚ö° AM√âLIORATION: ${metric.operation} prend ${metric.duration.toFixed(0)}ms - optimiser le prompt ou r√©duire la taille`;
      }
    }
    
    if (metric.duration > 1000) {
      return `üîß OPTIMISATION: ${metric.operation} prend ${metric.duration.toFixed(0)}ms - optimiser l'algorithme`;
    }
    
    return `‚úÖ OK: ${metric.operation} performant (${metric.duration.toFixed(0)}ms)`;
  }

  /**
   * R√©initialise le profiler
   */
  reset(): void {
    this.metrics = [];
    this.currentOperation = null;
    this.startTime = 0;
    this.llmCallCount = 0;
  }

  /**
   * Exporte les m√©triques en JSON
   */
  exportMetrics(): string {
    return JSON.stringify({
      timestamp: new Date().toISOString(),
      report: this.getReport()
    }, null, 2);
  }
}

/**
 * OperationTracker - Tracker d'op√©rations avec profiler
 */
export class OperationTracker {
  private profiler: PerformanceProfiler;

  constructor(profiler: PerformanceProfiler) {
    this.profiler = profiler;
  }

  /**
   * Track un appel LLM
   */
  async trackLLMCall(operation: string, llmFunction: () => Promise<any>): Promise<any> {
    this.profiler.startOperation(`LLM_${operation}`);
    
    try {
      const result = await llmFunction();
      const metric = this.profiler.endOperation();
      this.profiler.recordLLMCall(`LLM_${operation}`, {
        model: 'gemini-1.5-flash',
        success: true,
        resultType: typeof result
      });
      return result;
    } catch (error) {
      this.profiler.endOperation();
      this.profiler.recordLLMCall(`LLM_${operation}`, {
        model: 'gemini-1.5-flash',
        success: false,
        error: error.message
      });
      throw error;
    }
  }

  /**
   * Track une op√©ration de compression
   */
  async trackCompression(operation: string, compressionFunction: () => Promise<any>): Promise<any> {
    this.profiler.startOperation(`COMPRESSION_${operation}`);
    
    try {
      const result = await compressionFunction();
      const metric = this.profiler.endOperation();
      metric.details = {
        level: result.level,
        itemsCompressed: result.itemsCompressed,
        compressionRatio: result.compressionRatio
      };
      return result;
    } catch (error) {
      this.profiler.endOperation();
      throw error;
    }
  }

  /**
   * Track une op√©ration de recherche
   */
  async trackSearch(operation: string, searchFunction: () => Promise<any>): Promise<any> {
    this.profiler.startOperation(`SEARCH_${operation}`);
    
    try {
      const result = await searchFunction();
      const metric = this.profiler.endOperation();
      metric.details = {
        query: result.query,
        resultsCount: result.results?.length || 0,
        levelsSearched: result.levelsSearched || []
      };
      return result;
    } catch (error) {
      this.profiler.endOperation();
      throw error;
    }
  }
}

/**
 * PerformanceArtifactGenerator - G√©n√©rateur d'artefacts de performance
 */
export class PerformanceArtifactGenerator {
  generatePerformanceReport(profiler: PerformanceProfiler): string {
    const report = profiler.getReport();
    
    return `# Rapport de Performance - ${new Date().toISOString()}

## üìä M√©triques Globales
- **Dur√©e totale** : ${report.totalDuration.toFixed(2)}ms
- **Op√©rations** : ${report.summary.totalOperations}
- **Appels LLM** : ${report.summary.totalLLMCalls}
- **Dur√©e moyenne** : ${report.summary.averageDuration.toFixed(2)}ms
- **Pic m√©moire** : ${(report.summary.memoryPeak / 1024 / 1024).toFixed(2)}MB

## üîç Op√©rations Lourdes
${report.operations
  .sort((a, b) => b.duration - a.duration)
  .slice(0, 10)
  .map(op => `
### ${op.operation}
- **Dur√©e** : ${op.duration.toFixed(2)}ms
- **Appels LLM** : ${op.llmCalls}
- **M√©moire** : ${(op.memoryUsage / 1024 / 1024).toFixed(2)}MB
- **D√©tails** : ${JSON.stringify(op.details, null, 2)}
`).join('\n')}

## ‚ö†Ô∏è Goulots d'√âtranglement
${report.bottlenecks.map(bottleneck => `
- **${bottleneck.operation}** : ${bottleneck.duration.toFixed(2)}ms (${bottleneck.percentage.toFixed(1)}%)
  - ${bottleneck.recommendation}
`).join('\n')}

## üí° Recommandations
${report.recommendations.map(rec => `
- ${rec}
`).join('\n')}

## üìà Analyse
- **Op√©ration la plus lente** : ${report.operations.sort((a, b) => b.duration - a.duration)[0]?.operation} (${report.operations.sort((a, b) => b.duration - a.duration)[0]?.duration.toFixed(2)}ms)
- **Op√©ration avec le plus d'appels LLM** : ${report.operations.sort((a, b) => b.llmCalls - a.llmCalls)[0]?.operation} (${report.operations.sort((a, b) => b.llmCalls - a.llmCalls)[0]?.llmCalls} appels)
- **Efficacit√© LLM** : ${report.summary.totalLLMCalls > 0 ? (report.totalDuration / report.summary.totalLLMCalls).toFixed(2) : 'N/A'}ms par appel LLM
`;
  }
}