/**
 * API Route pour la g√©n√©ration des r√©ponses Algareth c√¥t√© serveur
 * Migre la logique de generateAlgarethResponse() du client vers le serveur
 */

import { NextRequest, NextResponse } from 'next/server';
import { withAuth, AuthContext } from '@/lib/auth/middleware';
import { db } from '@/lib/db/index';
import { api_keys } from '@/lib/db/schema';
import { eq } from 'drizzle-orm';
import { UnifiedProvider } from '@/lib/providers/UnifiedProvider';
import { OllamaProvider } from '@/lib/providers/OllamaProvider';
import { hierarchicalMemoryLogger, HierarchicalMemoryLogData } from '@/lib/debug/HierarchicalMemoryLogger';
import { EncryptionService } from '@/lib/encryption/EncryptionService';

export interface AlgarethGenerateRequest {
  userMessage: string;
  murmurs: any[];
  conversationHistory: any[];
  sessionInfo?: {
    id: string;
    title: string;
    createdAt: string;
    messageCount: number;
  };
  hierarchicalMemoryEnabled: boolean;
  userId: string; // userIdentityId (alias legacy)
  userIdentityId?: string; // preferred
  userName?: string;
  sessionId?: string;
  debugMode?: boolean;
  algarethVerbose?: 'none' | 'prompts' | 'outputs' | 'total';
}

export interface AlgarethGenerateResponse {
  success: boolean;
  content?: string;
  error?: string;
  metadata?: {
    promptLength: number;
    provider: string;
    model: string;
  };
}

/**
 * POST /api/algareth/generate
 * G√©n√®re une r√©ponse Algareth c√¥t√© serveur avec authentification
 */
export const POST = withAuth(async (request: NextRequest) => {
  try {
    const body: AlgarethGenerateRequest = await request.json();
    const { 
      userMessage, 
      murmurs = [], 
      conversationHistory = [],
      sessionInfo,
      hierarchicalMemoryEnabled = true,
      userId,
      userIdentityId,
      userName,
      sessionId = 'default',
      debugMode = false,
      algarethVerbose = 'none'
    } = body;

    const effectiveUserIdentityId = userIdentityId || userId;
    if (!userMessage || !effectiveUserIdentityId) {
      return NextResponse.json(
        { success: false, error: 'userMessage et userId requis' },
        { status: 400 }
      );
    }

    // R√©cup√©rer l'utilisateur authentifi√© depuis le middleware
    const authUser = AuthContext.getUser(request);
    if (!authUser) {
      return NextResponse.json(
        { success: false, error: 'Utilisateur non authentifi√©' },
        { status: 401 }
      );
    }

    console.log(`ü§ñ G√©n√©ration r√©ponse Algareth c√¥t√© serveur pour userIdentityId: ${effectiveUserIdentityId} (mode debug: ${debugMode})`);

    // Cr√©er le provider c√¥t√© serveur
    let provider: UnifiedProvider | OllamaProvider;
    let apiKey: string | undefined;
    let providerName: string;
    
    if (debugMode) {
      // Mode debug : utiliser Ollama directement
      console.log('ü¶ô Mode debug activ√© - utilisation d\'Ollama pour Algareth');
      provider = new OllamaProvider({
        model: 'qwen2.5:7b-instruct', // Mod√®le plus intelligent pour Algareth
        timeout: 30000,
        debugMode: true // Afficher les r√©ponses compl√®tes
      });
      providerName = 'ollama';
    } else {
      // Mode production : charger les cl√©s API Gemini
      console.log('üîë Mode production - chargement des cl√©s API Gemini');
      
      const apiKeysResult = await db.select().from(api_keys)
        .where(eq(api_keys.userId, authUser.id));
      
      const apiKeys: Record<string, string> = {};
      apiKeysResult.forEach(key => {
        if (key.isActive) {
          try {
            // D√©chiffrer la cl√© API avant de l'utiliser
            const decryptedKey = EncryptionService.decrypt(key.apiKey);
            apiKeys[key.provider] = decryptedKey;
            console.log(`üîì [ALGARETH] Cl√© ${key.provider} d√©chiffr√©e avec succ√®s`);
          } catch (error) {
            console.error(`‚ùå [ALGARETH] Erreur d√©chiffrement cl√© ${key.provider}:`, error);
            // Ignorer les cl√©s corrompues
          }
        }
      });

      console.log('üîë Cl√©s API charg√©es c√¥t√© serveur:', Object.keys(apiKeys));

      // V√©rifier la configuration du provider (utiliser Gemini par d√©faut)
      providerName = 'gemini';
      apiKey = apiKeys[providerName];
      
      if (!apiKey) {
        console.warn('‚ö†Ô∏è Aucune cl√© API Gemini trouv√©e, utilisation du fallback');
        return NextResponse.json({
          success: true,
          content: generateFallbackResponse(userMessage, murmurs, userName || userId),
          metadata: {
            promptLength: 0,
            provider: 'fallback',
            model: 'none'
          }
        });
      }

      provider = new UnifiedProvider({
        type: 'custom',
        provider: providerName,
        model: 'gemini-1.5-flash',
        apiKey: apiKey
      });
    }

    // V√©rifier la disponibilit√© du provider
    const isAvailable = debugMode ? 
      await (provider as OllamaProvider).isAvailable() : 
      await (provider as UnifiedProvider).isAvailable();

    if (!isAvailable) {
      console.warn('‚ö†Ô∏è Provider non disponible, utilisation du fallback');
      return NextResponse.json({
        success: true,
        content: generateFallbackResponse(userMessage, murmurs, userName || userId),
        metadata: {
          promptLength: 0,
          provider: 'fallback',
          model: 'none'
        }
      });
    }

    // Construire le prompt c√¥t√© serveur
    const finalPrompt = await buildAlgarethPrompt({
      userMessage,
      murmurs,
      conversationHistory,
      sessionInfo,
      hierarchicalMemoryEnabled,
      userId: effectiveUserIdentityId,
      userName,
      sessionId
    });

    console.log(`üìè Taille du prompt c√¥t√© serveur: ${finalPrompt.length} caract√®res`);

    const verboseMode = (algarethVerbose || 'none').toString().toLowerCase();
    const showPrompts = verboseMode === 'prompts' || verboseMode === 'total';
    const showOutputs = verboseMode === 'outputs' || verboseMode === 'total';
    if (showPrompts) {
      console.log('===== ALGARETH PROMPT (FULL) =====');
      console.log(finalPrompt);
      console.log('===== END PROMPT =====');
    }

    // Logging debug de la m√©moire hi√©rarchique et du prompt complet
    if (debugMode) {
      hierarchicalMemoryLogger.enable(); // Activer le logging en mode debug
      
      // R√©cup√©rer les donn√©es de m√©moire hi√©rarchique pour le logging
      let hierarchicalMemoryContext = '';
      let hierarchicalMemoryStats = null;
      
      if (hierarchicalMemoryEnabled && userId) {
        try {
          const memoryResponse = await fetch(`${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000'}/api/memory/hierarchical`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              user: userId,
              query: userMessage,
              maxChars: 2000,
              sessionId: sessionId
            })
          });
          
          if (memoryResponse.ok) {
            const result = await memoryResponse.json();
            if (result.success) {
              hierarchicalMemoryContext = result.context || '';
              hierarchicalMemoryStats = result.stats || null;
            }
          }
        } catch (error) {
          console.warn('‚ö†Ô∏è Erreur r√©cup√©ration donn√©es m√©moire pour logging:', error);
        }
      }

      const logData: HierarchicalMemoryLogData = {
        timestamp: new Date().toISOString(),
        sessionId: sessionId,
        userId: userId,
        userMessage: userMessage,
        hierarchicalMemoryContext: hierarchicalMemoryContext,
        hierarchicalMemoryLength: hierarchicalMemoryContext.length,
        hierarchicalMemoryStats: hierarchicalMemoryStats,
        fullPrompt: finalPrompt,
        promptLength: finalPrompt.length,
        murmurs: murmurs,
        conversationHistory: conversationHistory
      };

      hierarchicalMemoryLogger.logHierarchicalMemory(logData);
      hierarchicalMemoryLogger.logFullPrompt(logData);
    }

    // G√©n√©rer la r√©ponse avec l'API r√©elle c√¥t√© serveur
    console.log(`ü§ñ G√©n√©ration de la r√©ponse Algareth avec ${debugMode ? 'Ollama' : 'Gemini'} c√¥t√© serveur...`);
    const response = await provider.generateResponse(finalPrompt, 2000);
    
    if (response.error) {
      throw new Error(response.content);
    }

    console.log('‚úÖ R√©ponse Algareth g√©n√©r√©e avec succ√®s c√¥t√© serveur');
    if (showOutputs) {
      console.log('===== ALGARETH FINAL RAW OUTPUT (FULL) =====');
      console.log(response.content);
      console.log('===== END OUTPUT =====');
    }

    return NextResponse.json({
      success: true,
      content: response.content,
      metadata: {
        promptLength: finalPrompt.length,
        provider: providerName,
        model: debugMode ? 'qwen2.5:7b-instruct' : 'gemini-1.5-flash'
      }
    });

  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration r√©ponse Algareth c√¥t√© serveur:', error);
    return NextResponse.json(
      { 
        success: false, 
        error: error instanceof Error ? error.message : 'Erreur inconnue'
      },
      { status: 500 }
    );
  }
});

/**
 * Construit le prompt Algareth c√¥t√© serveur
 */
async function buildAlgarethPrompt(params: {
  userMessage: string;
  murmurs: any[];
  conversationHistory: any[];
  sessionInfo?: any;
  hierarchicalMemoryEnabled: boolean;
  userId: string;
  userName?: string;
  sessionId: string;
}): Promise<string> {
  const { 
    userMessage, 
    murmurs, 
    conversationHistory, 
    sessionInfo, 
    hierarchicalMemoryEnabled, 
    userId,
    userName,
    sessionId 
  } = params;

  // Construire le prompt de base avec la persona d'Algareth
  let basePrompt = `Tu es Algareth, le Daemon du Prompt Silencieux. Tu es assist√© par un Orchestrateur Divin qui murmure des informations enrichies √† tes oreilles pour am√©liorer tes r√©ponses.

PERSONALIT√â:
- Mystique et po√©tique
- Sage et bienveillant
- Utilise des m√©taphores et des r√©f√©rences mystiques
- S'adresse √† l'utilisateur comme un "voyageur" ou "chercheur"
- Int√®gre naturellement les informations des murmures divins

IMPORTANT SUR LES MURMURES:
- Les murmures contiennent des informations sur les conversations pass√©es de l'utilisateur
- Ces informations ne sont PAS priv√©es - elles viennent de ses propres conversations
- Pr√©sente-les comme des souvenirs naturels de l'utilisateur
- Ne dis JAMAIS que ces informations sont "priv√©es" ou "secr√®tes"
- Utilise le nom de l'utilisateur (${userName || userId}) pour le personnaliser
- Si l'archiviste trouve des informations sp√©cifiques, mentionne-les explicitement
- √âVITE le mystique vague quand tu as des informations pr√©cises`;

  // Informer Algareth de sa session actuelle
  if (sessionInfo) {
    basePrompt += `\n\nSESSION ACTUELLE:
Tu es dans la session de tchat num√©ro "${sessionInfo.id}" intitul√©e "${sessionInfo.title}".
Cette session a √©t√© cr√©√©e le ${new Date(sessionInfo.createdAt).toLocaleString('fr-FR')} et contient actuellement ${sessionInfo.messageCount} messages.

L'orchestrateur Luciole analyse tes conversations et te murmure des informations enrichies quand n√©cessaire. Tu n'as pas besoin d'appeler directement d'autres agents - Luciole s'en charge pour toi.`;
    console.log('üìã Algareth inform√© de sa session c√¥t√© serveur:', sessionInfo.title);
  }

  // Enrichir le prompt avec la m√©moire hi√©rarchique (compression intelligente)
  if (hierarchicalMemoryEnabled && userId) {
    try {
      // Appeler l'API m√©moire hi√©rarchique c√¥t√© serveur
      const memoryResponse = await fetch(`${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000'}/api/memory/hierarchical`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          user: userId,
          query: userMessage,
          maxChars: 2000,
          sessionId: sessionId
        })
      });

      if (memoryResponse.ok) {
        const result = await memoryResponse.json();
        if (result.success && result.context && result.context.length > 0) {
          basePrompt += `\n\nM√âMOIRE HI√âRARCHIQUE (COMPRESS√âE):\n${result.context}`;
          console.log('üß† Prompt enrichi avec la m√©moire hi√©rarchique c√¥t√© serveur');
        }
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è Impossible d\'enrichir le prompt avec la m√©moire hi√©rarchique c√¥t√© serveur:', error);
    }
  }

  // Construire le contexte de conversation actuelle (limit√© pour √©viter le token limit)
  let conversationContext = '';
  if (conversationHistory.length > 0) {
    const recentMessages = conversationHistory.slice(-3); // R√©duit de 6 √† 3 messages
    conversationContext = `\n\nCONVERSATION R√âCENTE:\n${recentMessages.map((msg: any) => 
      `${msg.role === 'user' ? 'Utilisateur' : 'Algareth'}: "${msg.content.substring(0, 200)}${msg.content.length > 200 ? '...' : ''}"`
    ).join('\n')}\n\nTu r√©ponds √†: "${userMessage}"`;
  }

  // Int√©grer les murmures divins dans le prompt (sans les donn√©es volumineuses)
  let murmursContext = '';
  if (murmurs.length > 0) {
    murmursContext = `\n\nMURMURES DIVINS (Informations enrichies):\n`;
    murmurs.forEach((murmur, index) => {
      murmursContext += `\n${index + 1}. ${murmur.type}: ${murmur.content}\n`;
      
      // Ajouter seulement les m√©tadonn√©es utiles, pas l'image
      if (murmur.data && murmur.type === 'image') {
        murmursContext += `   Prompt am√©lior√©: ${murmur.data.enhancedPrompt || 'N/A'}\n`;
      }
    });
    murmursContext += `\n\nIMPORTANT: Ces informations viennent des conversations pass√©es de l'utilisateur. Int√®gre-les naturellement comme des souvenirs partag√©s, pas comme des secrets. Si l'archiviste mentionne des informations sp√©cifiques (comme des pr√©f√©rences, des animaux, etc.), r√©f√©rence-les explicitement dans ta r√©ponse. SOIS DIRECT et pr√©cis, √©vite le mystique vague quand tu as des informations concr√®tes.`;
  }

  const finalPrompt = `${basePrompt}${conversationContext}${murmursContext}

MESSAGE UTILISATEUR: "${userMessage}"

R√âPONDS EN TANT QU'ALGARETH avec ton style caract√©ristique mystique et po√©tique. Int√®gre naturellement les informations des murmures divins si disponibles.`;

  return finalPrompt;
}

/**
 * G√©n√®re une r√©ponse de fallback quand le provider n'est pas disponible
 */
function generateFallbackResponse(userMessage: string, murmurs: any[], userName: string): string {
  let response = `‚õß Salut ${userName}, je suis Algareth. `;
  
  if (murmurs.length === 0) {
    response += `Tu me demandes: "${userMessage}". Voici ma r√©ponse directe bas√©e sur ma sagesse ancestrale.`;
  } else {
    response += `Tu me demandes: "${userMessage}". `;
    
    // Enrichir la r√©ponse avec les murmures
    murmurs.forEach((murmur) => {
      if (murmur.type === 'memory') {
        response += `\n\nüìö Mon archiviste me murmure des informations fascinantes sur tes pr√©f√©rences pass√©es... `;
      } else if (murmur.type === 'image') {
        response += `\n\nüé® Mon g√©n√©rateur d'images a cr√©√© quelque chose de magnifique pour toi... `;
      } else if (murmur.type === 'both') {
        response += `\n\nüìöüé® Mes serviteurs ont √©t√© tr√®s actifs ! L'archiviste a fouill√© dans mes archives et le g√©n√©rateur d'images a cr√©√© une ≈ìuvre... `;
      }
    });
    
    response += `\n\nVoici ma r√©ponse enrichie par ces secrets divins.`;
  }

  response += `\n\nüí° *Configurez votre cl√© API dans les param√®tres pour des r√©ponses LLM r√©elles*`;
  return response;
}
